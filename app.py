import sys
import os
os.environ["STREAMLIT_WATCH_MODULES"] = "false"
if 'STREAMLIT_RUN_MUTED' not in os.environ:
    os.environ['STREAMLIT_RUN_MUTED'] = 'true'
# L·∫•y ƒë∆∞·ªùng d·∫´n tuy·ªát ƒë·ªëi c·ªßa th∆∞ m·ª•c g·ªëc
ROOT_DIR = os.path.dirname(os.path.abspath(__file__))

# Th√™m c√°c th∆∞ m·ª•c c·∫ßn thi·∫øt v√†o PYTHONPATH
sys.path.insert(0, ROOT_DIR)
sys.path.insert(0, os.path.join(ROOT_DIR, "src"))
sys.path.insert(0, os.path.join(ROOT_DIR, "dictionary"))

# Fixes for PyTorch and Streamlit compatibility issues
os.environ["STREAMLIT_WATCH_MODULES"] = "false"

# Disable Streamlit's file watcher to avoid PyTorch class issues
if 'STREAMLIT_RUN_MUTED' not in os.environ:
    os.environ['STREAMLIT_RUN_MUTED'] = 'true'

import streamlit as st
import json
from word_analysis import analyze_word_sentiment
from sentence_analysis import SentenceAnalyzer
from dictionary.dict_manager import DictionaryManager
import pandas as pd
from io import StringIO
from docx import Document
import datetime

def add_word(word, score):
    # Validate input
    if not (-1 <= score <= 1):
        st.error("ƒêi·ªÉm s·ªë ph·∫£i trong kho·∫£ng [-1, 1]")
        return False
    
    # C·∫≠p nh·∫≠t t·ª´ ƒëi·ªÉn s·ª≠ d·ª•ng DictionaryManager
    success = dict_manager.add_word_to_sentiment_dict(word, score)
    
    if success:
        # Trigger re-render
        st.session_state.update_trigger = not st.session_state.get('update_trigger', False)
        # Hi·ªÉn th·ªã th√¥ng b√°o
        st.success(f"ƒê√£ th√™m t·ª´ '{word}' v·ªõi ƒëi·ªÉm {score}")
        return True
    else:
        st.error(f"C√≥ l·ªói khi l∆∞u t·ª´ '{word}' v√†o t·ª´ ƒëi·ªÉn")
        return False


def reload_dictionaries():
    """Reload all dictionaries from JSON files"""
    global dict_manager
    dict_manager.load_all()

# Kh·ªüi t·∫°o Dictionary Manager
dict_manager = DictionaryManager(os.path.join(ROOT_DIR, "dictionary"))

# L·∫•y c√°c t·ª´ ƒëi·ªÉn
SENTIMENT_DICT = dict_manager.get_sentiment_dict()
NEGATION_WORDS = dict_manager.get_negation_words()
INTENSIFIER_WORDS = dict_manager.get_intensifier_words()
DIMINISHER_WORDS = dict_manager.get_diminisher_words()
COMPOUND_WORDS = dict_manager.get_compound_words()
PROVERBS = dict_manager.get_proverbs()
PUNCTUATION_ANALYSIS = dict_manager.get_punctuation_analysis()

# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Ph√¢n t√≠ch c·∫£m x√∫c ti·∫øng Vi·ªát",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# Kh·ªüi t·∫°o session state
if 'sentence_analyzer' not in st.session_state:
    st.session_state.sentence_analyzer = SentenceAnalyzer()

# L∆∞u l·ªãch s·ª≠ ph√¢n t√≠ch v√†o session state
if 'analysis_history' not in st.session_state:
    st.session_state.analysis_history = []

# H√†m l∆∞u l·ªãch s·ª≠ ph√¢n t√≠ch
def get_status_from_sentiment(sentence_result):
    # X√°c ƒë·ªãnh tr·∫°ng th√°i d·ª±a tr√™n c·∫£m x√∫c ch√≠nh
    if isinstance(sentence_result, dict):
        main = sentence_result.get('main_sentiment')
        if main:
            if 't√≠ch c·ª±c' in main.lower() or 'positive' in main.lower():
                return 'T√≠ch c·ª±c'
            elif 'ti√™u c·ª±c' in main.lower() or 'negative' in main.lower():
                return 'Ti√™u c·ª±c'
            elif 'trung l·∫≠p' in main.lower() or 'neutral' in main.lower():
                return 'Trung l·∫≠p'
    return 'Kh√¥ng x√°c ƒë·ªãnh'

def save_analysis_history(text, word_result, sentence_result):
    status = get_status_from_sentiment(sentence_result)
    st.session_state.analysis_history.append({
        'timestamp': datetime.datetime.now().strftime('%Y-%m-%d %H:%M:%S'),
        'text': text,
        'word_result': word_result,
        'sentence_result': sentence_result,
        'status': status
    })

# H√†m xu·∫•t b√°o c√°o ra file docx
def export_report_docx(history):
    doc = Document()
    doc.add_heading('B√°o c√°o l·ªãch s·ª≠ ph√¢n t√≠ch c·∫£m x√∫c', 0)
    for entry in history:
        doc.add_heading(f"Th·ªùi gian: {entry['timestamp']}", level=1)
        doc.add_paragraph(f"VƒÉn b·∫£n: {entry['text']}")
        doc.add_paragraph(f"Tr·∫°ng th√°i: {entry.get('status', 'Kh√¥ng x√°c ƒë·ªãnh')}")
        doc.add_heading('K·∫øt qu·∫£ ph√¢n t√≠ch t·ª´:', level=2)
        for word in entry['word_result']['words']:
            doc.add_paragraph(f"- {word['word']}: {word['score']} ({word.get('type','')})")
        doc.add_heading('K·∫øt qu·∫£ ph√¢n t√≠ch c√¢u:', level=2)
        doc.add_paragraph(str(entry['sentence_result']))
    buffer = StringIO()
    doc.save('report.docx')
    return 'report.docx'

# H√†m gi·∫£ l·∫≠p hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh
@st.cache_data(show_spinner=False)
def retrain_model(train_data):
    # Placeholder: Th·ª±c t·∫ø s·∫Ω g·ªçi script hu·∫•n luy·ªán, l∆∞u model m·ªõi
    import time
    time.sleep(2)
    return 'Hu·∫•n luy·ªán l·∫°i m√¥ h√¨nh th√†nh c√¥ng!'

# T·∫°o tabs cho ·ª©ng d·ª•ng
tab1, tab2, tab3 = st.tabs(["Ph√¢n t√≠ch c·∫£m x√∫c", "Hu·∫•n luy·ªán m√¥ h√¨nh", "Th·ªëng k√™ & B√°o c√°o"])

with tab1:
    # Ti√™u ƒë·ªÅ v√† m√¥ t·∫£
    st.title("Ph√¢n t√≠ch c·∫£m x√∫c ti·∫øng Vi·ªát")
    st.markdown("""
        ·ª®ng d·ª•ng ph√¢n t√≠ch c·∫£m x√∫c vƒÉn b·∫£n ti·∫øng Vi·ªát, h·ªó tr·ª£:
        - Ph√¢n t√≠ch t·ª´ng t·ª´ v√† c·ª•m t·ª´
        - X√°c ƒë·ªãnh c·∫£m x√∫c t√≠ch c·ª±c, ti√™u c·ª±c, trung l·∫≠p
        - Hi·ªÉn th·ªã k·∫øt qu·∫£ tr·ª±c quan
    """)

    # √î nh·∫≠p vƒÉn b·∫£n
    text = st.text_area("Nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch:", height=100, help="Nh·∫≠p vƒÉn b·∫£n ti·∫øng Vi·ªát c·∫ßn ph√¢n t√≠ch c·∫£m x√∫c")

    # X·ª≠ l√Ω ph√¢n t√≠ch
    if st.button("Ph√¢n t√≠ch c·∫£m x√∫c"):
        if not text.strip():
            st.warning("‚ö†Ô∏è Vui l√≤ng nh·∫≠p vƒÉn b·∫£n c·∫ßn ph√¢n t√≠ch!")
        else:
            try:
                with st.spinner('ƒêang ph√¢n t√≠ch...'):
                    # Ph√¢n t√≠ch t·ª´ ng·ªØ
                    word_analysis = analyze_word_sentiment(text)
                    
                    
                    # Ph√¢n t√≠ch c√¢u vƒÉn
                    sentence_analysis = st.session_state.sentence_analyzer.analyze_sentence(text, word_analysis)
                    
                    # Hi·ªÉn th·ªã k·∫øt qu·∫£
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.subheader("üìù Ph√¢n t√≠ch t·ª´ng t·ª´")
                        
                        # T·∫°o b·∫£ng ph√¢n t√≠ch t·ª´
                        word_data = []
                        total_score = 0
                        
                        # L∆∞u ƒëi·ªÉm s·ªë tr∆∞·ªõc khi x·ª≠ l√Ω d·∫•u c√¢u
                        pre_punct_score = 0
                        punct_effect = 0
                        
                        for word in word_analysis["words"]:
                            # X√°c ƒë·ªãnh lo·∫°i t·ª´
                            word_type_display = {
                                "positive": "T√≠ch c·ª±c üü¢",
                                "negative": "Ti√™u c·ª±c üî¥",
                                "neutral": "Trung l·∫≠p ‚ö™",
                                "negation": "Ph·ªß ƒë·ªãnh ‚ùå",
                                "intensifier": "TƒÉng c∆∞·ªùng ‚¨ÜÔ∏è",
                                "diminisher": "Gi·∫£m nh·∫π ‚¨áÔ∏è",
                                "compound": "C·ª•m t·ª´ üî§",
                                "T√≠ch c·ª±c üü¢": "T√≠ch c·ª±c üü¢",
                                "Ti√™u c·ª±c üî¥": "Ti√™u c·ª±c üî¥",
                                "Trung l·∫≠p ‚ö™": "Trung l·∫≠p ‚ö™"
                            }.get(word["type"], word["type"])
                            
                            # X√°c ƒë·ªãnh lo·∫°i c·∫£m x√∫c d·ª±a v√†o ƒëi·ªÉm s·ªë
                            sentiment_type = "Trung l·∫≠p ‚ö™"
                            if word["score"] > 0:
                                sentiment_type = "T√≠ch c·ª±c üü¢"
                            elif word["score"] < 0:
                                sentiment_type = "Ti√™u c·ª±c üî¥"
                                
                            # L∆∞u c√°c th√¥ng tin v·ªÅ lo·∫°i t·ª´ v√†o ph·∫ßn m√¥ t·∫£
                            type_info = word_type_display
                            if "description" not in word or not word["description"]:
                                word["description"] = type_info
                            
                            # Th√™m m√¥ t·∫£ n·∫øu c√≥
                            description = word.get("description", "")
                            
                            # N·∫øu t·ª´ l√† bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c, l·∫•y m√¥ t·∫£ t·ª´ PUNCTUATION_ANALYSIS
                            if word["word"] in PUNCTUATION_ANALYSIS:
                                emoji_info = PUNCTUATION_ANALYSIS[word["word"]]
                                if "description" in emoji_info:
                                    description = emoji_info["description"]
                                
                                # Hi·ªÉn th·ªã lo·∫°i c·∫£m x√∫c d·ª±a tr√™n effect
                                if "effect" in emoji_info:
                                    if emoji_info["effect"] == "positive":
                                        sentiment_type = "T√≠ch c·ª±c üü¢"
                                    elif emoji_info["effect"] == "negative":
                                        sentiment_type = "Ti√™u c·ª±c üî¥"
                                
                                # Hi·ªÉn th·ªã gi√° tr·ªã ch√≠nh x√°c t·ª´ PUNCTUATION_ANALYSIS n·∫øu c√≥
                                if "value" in emoji_info:
                                    word["score"] = emoji_info["value"]  # C·∫≠p nh·∫≠t ƒëi·ªÉm m·ªõi
                            
                            # C·ªông ƒëi·ªÉm cho t·∫•t c·∫£ c√°c lo·∫°i t·ª´ v√† d·∫•u c√¢u
                            total_score += word["score"]
                            
                            # Th√™m v√†o b·∫£ng d·ªØ li·ªáu
                            word_data.append({
                                "T·ª´/C·ª•m t·ª´": word["word"],
                                "Lo·∫°i": sentiment_type,
                                "ƒêi·ªÉm": f"{word['score']:.2f}",
                                "M√¥ t·∫£": description
                            })
                        
                        # C·∫≠p nh·∫≠t t·ªïng ƒëi·ªÉm trong word_analysis
                        word_analysis['score'] = total_score
                        
                        st.table(word_data)
                        
                        # Hi·ªÉn th·ªã t·ªïng ƒëi·ªÉm
                        st.metric("T·ªïng ƒëi·ªÉm", f"{word_analysis['score']:.2f}")
                        
                        # Hi·ªÉn th·ªã th√¥ng tin v·ªÅ ·∫£nh h∆∞·ªüng c·ªßa d·∫•u c√¢u n·∫øu c√≥
                        if "pre_punct_score" in word_analysis and "punct_effect" in word_analysis:
                            pre_punct_score = word_analysis["pre_punct_score"]
                            punct_effect = word_analysis["punct_effect"]
                            
                            col1a, col1b = st.columns(2)
                            with col1a:
                                st.metric("ƒêi·ªÉm tr∆∞·ªõc d·∫•u c√¢u", f"{pre_punct_score:.2f}")
                            with col1b:
                                st.metric("·∫¢nh h∆∞·ªüng d·∫•u c√¢u", f"{punct_effect:.2f}", 
                                         delta_color="normal" if punct_effect == 0 else "off")
                    
                    with col2:
                        st.subheader("üìä Ph√¢n t√≠ch to√†n c√¢u")
                        
                        # T√≠nh t·ªïng ƒëi·ªÉm tuy·ªát ƒë·ªëi c·ªßa t·∫•t c·∫£ c√°c t·ª´ c√≥ ƒëi·ªÉm kh√°c 0
                        total_abs = sum(abs(word["score"]) for word in word_analysis["words"] if word["score"] != 0)
                        
                        # Ch·ªâ t√≠nh c√°c t·ª´ c√≥ ƒëi·ªÉm kh√°c 0
                        meaningful_words = [word for word in word_analysis["words"] if word["score"] != 0]
                        
                        if total_abs > 0:
                            # T√≠nh t·ªïng ƒëi·ªÉm t√≠ch c·ª±c v√† ti√™u c·ª±c
                            positive_score = sum(word["score"] for word in word_analysis["words"] if word["score"] > 0)
                            negative_score = abs(sum(word["score"] for word in word_analysis["words"] if word["score"] < 0))
                            
                            sentiment_data = {
                                "T√≠ch c·ª±c üü¢": positive_score,
                                "Ti√™u c·ª±c üî¥": negative_score
                            }
                            
                            # Ch·ªâ th√™m trung l·∫≠p n·∫øu c√≥ t·ª´ trung l·∫≠p c√≥ √Ω nghƒ©a
                            neutral_score = sum(1 for word in meaningful_words 
                                             if abs(word["score"]) <= 0.1) / len(meaningful_words) if meaningful_words else 0
                            
                            if neutral_score > 0:
                                sentiment_data["Trung l·∫≠p ‚ö™"] = neutral_score
                            
                            # Chu·∫©n h√≥a ƒë·ªÉ t·ªïng = 1
                            total = sum(sentiment_data.values())
                            if total > 0:
                                for key in sentiment_data:
                                    sentiment_data[key] = sentiment_data[key] / total
                        else:
                            sentiment_data = {
                                "T√≠ch c·ª±c üü¢": 0,
                                "Ti√™u c·ª±c üî¥": 0,
                                "Trung l·∫≠p ‚ö™": 1
                            }
                        
                        # X√°c ƒë·ªãnh c·∫£m x√∫c ch√≠nh v√† t√≠nh ƒë·ªô tin c·∫≠y
                        if total_abs > 0:
                            # T√≠nh t·ª∑ l·ªá ƒëi·ªÉm s·ªë
                            positive_ratio = sum(word["score"] for word in word_analysis["words"] if word["score"] > 0) / total_abs
                            negative_ratio = abs(sum(word["score"] for word in word_analysis["words"] if word["score"] < 0)) / total_abs
                            
                            # X√°c ƒë·ªãnh c·∫£m x√∫c ch√≠nh d·ª±a tr√™n t·ªïng ƒëi·ªÉm th·ª±c t·∫ø
                            # S·ª≠ d·ª•ng total_score t·ª´ word_analysis t·ª´ result
                            final_score = word_analysis["score"]
                            if final_score < -0.1:  # Ng∆∞·ª°ng ti√™u c·ª±c
                                main_sentiment = "Ti√™u c·ª±c üî¥"
                                # ƒê·ªô tin c·∫≠y d·ª±a tr√™n m·ª©c ƒë·ªô ti√™u c·ª±c v√† t·ª∑ l·ªá t·ª´ ti√™u c·ª±c
                                confidence = min(abs(final_score) * 50, 100) * negative_ratio
                            elif final_score > 0.1:  # Ng∆∞·ª°ng t√≠ch c·ª±c
                                main_sentiment = "T√≠ch c·ª±c üü¢"
                                # ƒê·ªô tin c·∫≠y d·ª±a tr√™n m·ª©c ƒë·ªô t√≠ch c·ª±c v√† t·ª∑ l·ªá t·ª´ t√≠ch c·ª±c
                                confidence = min(final_score * 50, 100) * positive_ratio
                            else:
                                main_sentiment = "Trung l·∫≠p ‚ö™"
                                # ƒê·ªô tin c·∫≠y trung l·∫≠p d·ª±a tr√™n m·ª©c ƒë·ªô c√¢n b·∫±ng gi·ªØa t√≠ch c·ª±c v√† ti√™u c·ª±c
                                balance_factor = 1 - abs(positive_ratio - negative_ratio)
                                confidence = balance_factor * 80  # Gi·∫£m ƒë·ªô tin c·∫≠y t·ªëi ƒëa xu·ªëng 80% cho trung l·∫≠p
                        else:
                            # N·∫øu kh√¥ng c√≥ ƒëi·ªÉm s·ªë c√≥ √Ω nghƒ©a, th√¨ l√† trung l·∫≠p v·ªõi ƒë·ªô tin c·∫≠y v·ª´a ph·∫£i
                            main_sentiment = "Trung l·∫≠p ‚ö™"
                            confidence = 70.0  # Gi·∫£m ƒë·ªô tin c·∫≠y xu·ªëng 70% khi kh√¥ng c√≥ t·ª´ c√≥ √Ω nghƒ©a
                        
                        # Gi·ªõi h·∫°n ƒë·ªô tin c·∫≠y trong kho·∫£ng 0-100%
                        confidence = min(max(confidence, 0.0), 100.0)
                        
                        # Hi·ªÉn th·ªã k·∫øt qu·∫£ ch√≠nh
                        st.metric(
                            "C·∫£m x√∫c ch√≠nh",
                            main_sentiment,
                            f"ƒê·ªô tin c·∫≠y: {confidence:.1f}%"
                        )
                        
                        # V·∫Ω bi·ªÉu ƒë·ªì
                        chart = st.bar_chart(sentiment_data)
                        
                        # Th·ªëng k√™ chi ti·∫øt
                        st.markdown("**Chi ti·∫øt ph√¢n t√≠ch:**")
                        stats = {
                            "S·ªë t·ª´ ph√¢n t√≠ch": len([w for w in word_analysis["words"] 
                                                  if w["type"] not in ["intensifier", "diminisher", "negation"]]),
                            "T·ª´ t√≠ch c·ª±c": sum(1 for w in word_analysis["words"] if w["score"] > 0),
                            "T·ª´ ti√™u c·ª±c": sum(1 for w in word_analysis["words"] if w["score"] < 0),
                            "T·ª´ trung l·∫≠p": sum(1 for w in word_analysis["words"] 
                                              if w["score"] == 0 and w["type"] not in ["intensifier", "diminisher", "negation"])
                        }
                        st.write(stats)
                        
                save_analysis_history(text, word_analysis, sentence_analysis)
            except Exception as e:
                st.error(f"‚ùå C√≥ l·ªói x·∫£y ra: {str(e)}")
                st.error("Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c li√™n h·ªá h·ªó tr·ª£!")

with tab2:
    st.title("Hu·∫•n luy·ªán m√¥ h√¨nh")
    st.markdown("""
        Th√™m t·ª´ ng·ªØ m·ªõi ho·∫∑c bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c v√†o t·ª´ ƒëi·ªÉn ƒë·ªÉ c·∫£i thi·ªán kh·∫£ nƒÉng ph√¢n t√≠ch c·∫£m x√∫c.
    """)
    
    # T·∫°o c√°c tab cho c√°c lo·∫°i hu·∫•n luy·ªán kh√°c nhau
    train_tab1, train_tab2, train_tab3, train_tab4 = st.tabs(["‚ö° Th√™m t·ª´ ƒë∆°n m·ªõi", "üòä Th√™m bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c", "üë• Th√™m c·ª•m t·ª´", "üìú Th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ"])

with train_tab1:
    st.subheader("Th√™m t·ª´ ng·ªØ m·ªõi v√†o t·ª´ ƒëi·ªÉn")
    # Form nh·∫≠p t·ª´ m·ªõi
    with st.form("add_word_form"):
        new_word = st.text_input("Nh·∫≠p t·ª´ m·ªõi (CH·ªà NH·∫¨P M·ªòT T·ª™ ƒë∆°n l·∫ª):", placeholder="V√≠ d·ª•: tuy·ªát")
        sentiment_score = st.slider("ƒêi·ªÉm s·ªë:", min_value=-1.0, max_value=1.0, value=0.0, step=0.1, key="word_score_slider")
        # T·ª± ƒë·ªông x√°c ƒë·ªãnh lo·∫°i c·∫£m x√∫c d·ª±a tr√™n ƒëi·ªÉm s·ªë
        from config import SENTIMENT_CONFIG

        def determine_sentiment_type(score):
            # ƒê·∫£m b·∫£o ph√¢n lo·∫°i ch√≠nh x√°c v·ªõi ng∆∞·ª°ng 0.1
            if score >= 0.1:
                return 'T√≠ch c·ª±c'
            elif score <= -0.1:
                return 'Ti√™u c·ª±c'
            else:
                return 'Trung l·∫≠p'
        
        # S·ª≠ d·ª•ng gi√° tr·ªã hi·ªán t·∫°i c·ªßa slider
        sentiment_type = determine_sentiment_type(sentiment_score)
        st.write(f'**Lo·∫°i t·ª± ƒë·ªông:** {sentiment_type}')
        submit_word = st.form_submit_button("Th√™m t·ª´")
    if submit_word and new_word.strip():
        # Ki·ªÉm tra xem input c√≥ ph·∫£i t·ª´ ƒë∆°n kh√¥ng
        if len(new_word.split()) > 1:
            st.error(f"‚ùå '{new_word}' ch·ª©a nhi·ªÅu t·ª´! Vui l√≤ng ch·ªâ nh·∫≠p M·ªòT T·ª™ ƒë∆°n l·∫ª duy nh·∫•t. N·∫øu mu·ªën th√™m c·ª•m t·ª´, h√£y s·ª≠ d·ª•ng tab 'Th√™m c·ª•m t·ª´ m·ªõi'.")
        else:
            try:
                # Ki·ªÉm tra xem t·ª´ ƒë√£ t·ªìn t·∫°i ch∆∞a
                if new_word in SENTIMENT_DICT:
                    st.warning(f"‚ö†Ô∏è T·ª´ '{new_word}' ƒë√£ t·ªìn t·∫°i trong t·ª´ ƒëi·ªÉn!")
                else:
                    # Th√™m t·ª´ m·ªõi v√†o t·ª´ ƒëi·ªÉn b·∫±ng dictionary manager
                    if dict_manager.add_word_to_sentiment_dict(new_word, sentiment_score):
                        # C·∫≠p nh·∫≠t bi·∫øn to√†n c·ª•c
                        SENTIMENT_DICT = dict_manager.get_sentiment_dict()
                        
                        st.success(f"‚úÖ ƒê√£ th√™m t·ª´ '{new_word}' v·ªõi ƒëi·ªÉm s·ªë {sentiment_score} (lo·∫°i: {sentiment_type}) v√†o t·ª´ ƒëi·ªÉn!")
                        st.info("‚ÑπÔ∏è T·ª´ m·ªõi ƒë√£ ƒë∆∞·ª£c th√™m v√†o v√† s·∫µn s√†ng s·ª≠ d·ª•ng ngay l·∫≠p t·ª©c.")
                    else:
                        st.error("‚ùå Kh√¥ng th·ªÉ th√™m t·ª´ v√†o t·ª´ ƒëi·ªÉn!")
            except Exception as e:
                st.error(f"‚ùå C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t t·ª´ ƒëi·ªÉn: {str(e)}")

# Hi·ªÉn th·ªã danh s√°ch t·ª´ hi·ªán c√≥
    st.subheader("Danh s√°ch t·ª´ hi·ªán c√≥")
    search_word = st.text_input("T√¨m ki·∫øm t·ª´:", placeholder="Nh·∫≠p t·ª´ c·∫ßn t√¨m...")
    try:
        reload_dictionaries()
        updated_dict = dict_manager.get_sentiment_dict()
    except Exception:
        updated_dict = SENTIMENT_DICT
    if updated_dict:
        filtered_dict = {k: v for k, v in updated_dict.items() if not search_word or search_word.lower() in k.lower()}
        st.info(f"T√¨m th·∫•y {len(filtered_dict)} t·ª´" + (f" ch·ª©a '{search_word}'" if search_word else ""))
        if filtered_dict:
            word_table = []
            for word, score in filtered_dict.items():
                sentiment = "T√≠ch c·ª±c üü¢" if score >= 0.1 else "Ti√™u c·ª±c üî¥" if score <= -0.1 else "Trung l·∫≠p ‚ö™"
                word_table.append({"T·ª´/C·ª•m t·ª´": word, "ƒêi·ªÉm s·ªë": f"{score:.1f}", "Lo·∫°i": sentiment})
            st.table(word_table)
    else:
        st.error("Kh√¥ng th·ªÉ t·∫£i danh s√°ch t·ª´ t·ª´ SENTIMENT_DICT.")

with train_tab2:
    st.subheader("Th√™m bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c m·ªõi")
    # Form nh·∫≠p bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c m·ªõi
    with st.form("add_emoji_form"):
        new_emoji = st.text_input("Nh·∫≠p bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c:", placeholder="V√≠ d·ª•: üòä")
        emoji_value = st.slider("Gi√° tr·ªã c·∫£m x√∫c:", min_value=-1.0, max_value=1.0, value=0.0, step=0.1)
        # T·ª± ƒë·ªông x√°c ƒë·ªãnh lo·∫°i c·∫£m x√∫c d·ª±a tr√™n ƒëi·ªÉm s·ªë
        if emoji_value >= 0.1:
            auto_effect = "positive"
            effect_label = "T√≠ch c·ª±c"
        elif emoji_value <= -0.1:
            auto_effect = "negative"
            effect_label = "Ti√™u c·ª±c"
        else:
            auto_effect = "neutral"
            effect_label = "Trung l·∫≠p"
        st.write(f'**Lo·∫°i t·ª± ƒë·ªông:** {effect_label}')
        description = st.text_input("M√¥ t·∫£:", value=f"Emoji {effect_label.lower()} th·ªÉ hi·ªán c·∫£m x√∫c {effect_label.lower()}")
        submit_emoji = st.form_submit_button("Th√™m bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c")
    if submit_emoji and new_emoji.strip():
        try:
            # Ki·ªÉm tra xem bi·ªÉu t∆∞·ª£ng ƒë√£ t·ªìn t·∫°i ch∆∞a
            if new_emoji in PUNCTUATION_ANALYSIS:
                st.warning(f"‚ö†Ô∏è Bi·ªÉu t∆∞·ª£ng '{new_emoji}' ƒë√£ t·ªìn t·∫°i trong t·ª´ ƒëi·ªÉn!")
            else:
                # Th√™m bi·ªÉu t∆∞·ª£ng m·ªõi v√†o t·ª´ ƒëi·ªÉn b·∫±ng dictionary manager, d√πng auto_effect
                if dict_manager.add_emoji_to_punctuation(new_emoji, auto_effect, emoji_value, description):
                    # C·∫≠p nh·∫≠t bi·∫øn to√†n c·ª•c
                    PUNCTUATION_ANALYSIS = dict_manager.get_punctuation_analysis()
                    
                    st.success(f"‚úÖ ƒê√£ th√™m bi·ªÉu t∆∞·ª£ng '{new_emoji}' v√†o t·ª´ ƒëi·ªÉn!")
                    # Th√¥ng b√°o th√†nh c√¥ng
                    st.info("‚ÑπÔ∏è Bi·ªÉu t∆∞·ª£ng ƒë√£ ƒë∆∞·ª£c th√™m v√†o v√† s·∫µn s√†ng s·ª≠ d·ª•ng ngay l·∫≠p t·ª©c.")
                else:
                    st.error("‚ùå Kh√¥ng th·ªÉ th√™m bi·ªÉu t∆∞·ª£ng v√†o t·ª´ ƒëi·ªÉn!")
        except Exception as e:
            st.error(f"‚ùå C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t t·ª´ ƒëi·ªÉn: {str(e)}")
    # Hi·ªÉn th·ªã danh s√°ch bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c hi·ªán c√≥
    st.subheader("Danh s√°ch bi·ªÉu t∆∞·ª£ng c·∫£m x√∫c hi·ªán c√≥")
    try:
        reload_dictionaries()
        updated_punctuation = dict_manager.get_punctuation_analysis()
        # Hi·ªÉn th·ªã t·ª´ ƒëi·ªÉn d∆∞·ªõi d·∫°ng b·∫£ng
        emoji_table = []
        for emoji, info in updated_punctuation.items():
            # X·ª≠ l√Ω c·∫£ hai tr∆∞·ªùng h·ª£p: 'value' v√† 'multiplier'
            if "value" in info:
                score = info["value"]
            elif "multiplier" in info:
                score = info["multiplier"]
            else:
                score = 0.0
                
            sentiment = "T√≠ch c·ª±c üü¢" if info["effect"] == "positive" else "Ti√™u c·ª±c üî¥" if info["effect"] == "negative" else "Trung l·∫≠p ‚ö™"
            emoji_table.append({"Bi·ªÉu t∆∞·ª£ng": emoji, "ƒêi·ªÉm s·ªë": f"{score:.1f}", "Lo·∫°i": sentiment})
        st.table(emoji_table)
    except Exception as e:
        st.error(f"‚ùå C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t t·ª´ ƒëi·ªÉn: {str(e)}")

with train_tab3:
    st.subheader("Th√™m c·ª•m t·ª´ m·ªõi")
    # Form nh·∫≠p c·ª•m t·ª´ m·ªõi
    with st.form("add_compound_form"):
        new_compound = st.text_input("Nh·∫≠p c·ª•m t·ª´ m·ªõi:", placeholder="V√≠ d·ª•: kh√¥ng ng·ª´ng nh·ªõ")
        compound_score = st.slider("ƒêi·ªÉm s·ªë:", min_value=-1.0, max_value=1.0, value=0.0, step=0.1, key="compound_score_slider")
        
        # T·ª± ƒë·ªông x√°c ƒë·ªãnh lo·∫°i c·∫£m x√∫c d·ª±a tr√™n ƒëi·ªÉm s·ªë
        compound_type = "T√≠ch c·ª±c" if compound_score >= 0.1 else "Ti√™u c·ª±c" if compound_score <= -0.1 else "Trung l·∫≠p"
        st.write(f'**Lo·∫°i t·ª± ƒë·ªông:** {compound_type}')
        
        submit_compound = st.form_submit_button("Th√™m c·ª•m t·ª´")
    if submit_compound and new_compound.strip():
        try:
            # Ki·ªÉm tra xem c·ª•m t·ª´ ƒë√£ t·ªìn t·∫°i ch∆∞a
            if new_compound in COMPOUND_WORDS:
                st.warning(f"‚ö†Ô∏è C·ª•m t·ª´ '{new_compound}' ƒë√£ t·ªìn t·∫°i trong t·ª´ ƒëi·ªÉn!")
            else:
                # Th√™m c·ª•m t·ª´ m·ªõi v√†o t·ª´ ƒëi·ªÉn b·∫±ng dictionary manager
                if dict_manager.add_compound_word(new_compound, compound_score):
                    # C·∫≠p nh·∫≠t bi·∫øn to√†n c·ª•c
                    COMPOUND_WORDS = dict_manager.get_compound_words()
                    
                    st.success(f"‚úÖ ƒê√£ th√™m c·ª•m t·ª´ '{new_compound}' v·ªõi ƒëi·ªÉm s·ªë {compound_score} (lo·∫°i: {compound_type}) v√†o t·ª´ ƒëi·ªÉn!")
                    st.info("‚ÑπÔ∏è C·ª•m t·ª´ m·ªõi ƒë√£ ƒë∆∞·ª£c th√™m v√†o v√† s·∫µn s√†ng s·ª≠ d·ª•ng ngay l·∫≠p t·ª©c.")
                else:
                    st.error("‚ùå Kh√¥ng th·ªÉ th√™m c·ª•m t·ª´ v√†o t·ª´ ƒëi·ªÉn!")
        except Exception as e:
            st.error(f"‚ùå C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t t·ª´ ƒëi·ªÉn: {str(e)}")
    search_compound = st.text_input("T√¨m ki·∫øm c·ª•m t·ª´:", placeholder="Nh·∫≠p c·ª•m t·ª´ c·∫ßn t√¨m...", key="search_compound")
    try:
        reload_dictionaries()
        updated_compounds = dict_manager.get_compound_words()
    except Exception:
        updated_compounds = COMPOUND_WORDS
    # L·ªçc v√† hi·ªÉn th·ªã t·ª´ ƒëi·ªÉn
    filtered_compounds = {k: v for k, v in updated_compounds.items() if not search_compound or search_compound.lower() in k.lower()}
    # Hi·ªÉn th·ªã s·ªë l∆∞·ª£ng c·ª•m t·ª´
    st.info(f"T√¨m th·∫•y {len(filtered_compounds)} c·ª•m t·ª´" + (f" ch·ª©a '{search_compound}'" if search_compound else ""))
    # Hi·ªÉn th·ªã t·ª´ ƒëi·ªÉn d∆∞·ªõi d·∫°ng b·∫£ng
    if filtered_compounds:
        compound_table = []
        for word, score in filtered_compounds.items():
            sentiment = "T√≠ch c·ª±c üü¢" if score >= 0.1 else "Ti√™u c·ª±c üî¥" if score <= -0.1 else "Trung l·∫≠p ‚ö™"
            compound_table.append({"C·ª•m t·ª´": word, "ƒêi·ªÉm s·ªë": f"{score:.1f}", "Lo·∫°i": sentiment})
        st.table(compound_table)

# Tab th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ
with train_tab4:
    st.subheader("Th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ m·ªõi")
    # Form nh·∫≠p th√†nh ng·ªØ/t·ª•c ng·ªØ m·ªõi
    with st.form("add_proverb_form"):
        new_proverb = st.text_input("Nh·∫≠p th√†nh ng·ªØ/t·ª•c ng·ªØ m·ªõi:", placeholder="V√≠ d·ª•: ƒÉn qu·∫£ nh·ªõ k·∫ª tr·ªìng c√¢y")
        proverb_score = st.slider("ƒêi·ªÉm s·ªë:", min_value=-1.0, max_value=1.0, value=0.0, step=0.1, key="proverb_score_slider")
        
        # T·ª± ƒë·ªông x√°c ƒë·ªãnh lo·∫°i c·∫£m x√∫c d·ª±a tr√™n ƒëi·ªÉm s·ªë
        proverb_type = determine_sentiment_type(proverb_score)
        st.write(f'**Lo·∫°i t·ª± ƒë·ªông:** {proverb_type}')
        
        submit_proverb = st.form_submit_button("Th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ")
    if submit_proverb and new_proverb.strip():
        try:
            # Ki·ªÉm tra xem th√†nh ng·ªØ/t·ª•c ng·ªØ ƒë√£ t·ªìn t·∫°i ch∆∞a
            if new_proverb in PROVERBS:
                st.warning(f"‚ö†Ô∏è Th√†nh ng·ªØ/t·ª•c ng·ªØ '{new_proverb}' ƒë√£ t·ªìn t·∫°i trong t·ª´ ƒëi·ªÉn!")
            else:
                # Th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ m·ªõi v√†o t·ª´ ƒëi·ªÉn b·∫±ng dictionary manager
                success, message = dict_manager.add_proverb(new_proverb, proverb_score)
                if success:
                    # C·∫≠p nh·∫≠t bi·∫øn to√†n c·ª•c
                    reload_dictionaries()
                    
                    st.success(f"‚úÖ ƒê√£ th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ '{new_proverb}' v·ªõi ƒëi·ªÉm s·ªë {proverb_score} (lo·∫°i: {proverb_type}) v√†o t·ª´ ƒëi·ªÉn!")
                    st.info("‚ÑπÔ∏è Th√†nh ng·ªØ/t·ª•c ng·ªØ m·ªõi ƒë√£ ƒë∆∞·ª£c th√™m v√†o v√† s·∫µn s√†ng s·ª≠ d·ª•ng ngay l·∫≠p t·ª©c.")
                else:
                    st.error(f"‚ùå Kh√¥ng th·ªÉ th√™m th√†nh ng·ªØ/t·ª•c ng·ªØ v√†o t·ª´ ƒëi·ªÉn: {message}")
        except Exception as e:
            st.error(f"‚ùå C√≥ l·ªói x·∫£y ra khi c·∫≠p nh·∫≠t t·ª´ ƒëi·ªÉn: {str(e)}")
    search_proverb = st.text_input("T√¨m ki·∫øm th√†nh ng·ªØ/t·ª•c ng·ªØ:", placeholder="Nh·∫≠p th√†nh ng·ªØ/t·ª•c ng·ªØ c·∫ßn t√¨m...", key="search_proverb")
    try:
        reload_dictionaries()
        updated_proverbs = dict_manager.get_proverbs()
    except Exception:
        updated_proverbs = PROVERBS
    # L·ªçc v√† hi·ªÉn th·ªã t·ª´ ƒëi·ªÉn
    filtered_proverbs = {k: v for k, v in updated_proverbs.items() if not search_proverb or search_proverb.lower() in k.lower()}
    
    st.subheader("Danh s√°ch th√†nh ng·ªØ/t·ª•c ng·ªØ hi·ªán c√≥")
    st.write(f"T·ªïng s·ªë th√†nh ng·ªØ/t·ª•c ng·ªØ trong t·ª´ ƒëi·ªÉn: **{len(filtered_proverbs)}**")
    
    if filtered_proverbs:
        # T·∫°o b·∫£ng hi·ªÉn th·ªã d·ªØ li·ªáu
        proverb_table = []
        for word, score in filtered_proverbs.items():
            sentiment = "T√≠ch c·ª±c üü¢" if score >= 0.1 else "Ti√™u c·ª±c üî¥" if score <= -0.1 else "Trung l·∫≠p ‚ö™"
            proverb_table.append({"Th√†nh ng·ªØ/t·ª•c ng·ªØ": word, "ƒêi·ªÉm s·ªë": f"{score:.1f}", "Lo·∫°i": sentiment})
        st.table(proverb_table)

# Tab th·ªëng k√™ l·ªãch s·ª≠ v√† xu·∫•t b√°o c√°o
tab3 = st.tabs(["Th·ªëng k√™ & B√°o c√°o"])[0]
with tab3:
    st.header('L·ªãch s·ª≠ ph√¢n t√≠ch & Xu·∫•t b√°o c√°o')
    if st.session_state.analysis_history:
        df_history = pd.DataFrame([
            {'Th·ªùi gian': h['timestamp'], 'VƒÉn b·∫£n': h['text'], 'Tr·∫°ng th√°i': h.get('status', 'Kh√¥ng x√°c ƒë·ªãnh')} for h in st.session_state.analysis_history
        ])
        st.dataframe(df_history)
        if st.button('Xu·∫•t b√°o c√°o DOCX'):
            file_path = export_report_docx(st.session_state.analysis_history)
            with open(file_path, 'rb') as f:
                st.download_button('T·∫£i b√°o c√°o DOCX', f, file_name='bao_cao_phan_tich.docx')
    else:
        st.info('Ch∆∞a c√≥ l·ªãch s·ª≠ ph√¢n t√≠ch n√†o.')
